{"cells":[{"cell_type":"markdown","source":["# Introduction to DataFrames Lab - Solution\n## Distinct Articles"],"metadata":{}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Instructions\n\nIn the cell provided below, write the code necessary to count the number of distinct articles in our data set.\n0. Copy and paste all you like from the previous notebook.\n0. Read in our parquet files.\n0. Apply the necessary transformations.\n0. Assign the count to the variable `totalArticles`\n0. Run the last cell to verify that the data was loaded correctly.\n\n**Bonus**\n\nIf you recall from the beginning of the previous notebook, the act of reading in our parquet files will trigger a job.\n0. Define a schema that matches the data we are working with.\n0. Update the read operation to use the schema."],"metadata":{}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Show Your Work"],"metadata":{}},{"cell_type":"code","source":["(source, sasEntity, sasToken) = getAzureDataSource()\nspark.conf.set(sasEntity, sasToken)\n\npath = source + \"/wikipedia/pagecounts/staging_parquet_en_only_clean/\""],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# ANSWER\n\n# This version does not include the bonus.\n\nfrom pyspark.sql.types import *\n\nparquetDir = \"/mnt/training/wikipedia/pagecounts/staging_parquet_en_only_clean/\"\n\ndf = (spark\n  .read\n  .parquet(parquetDir)\n  .select(\"article\")\n  .distinct()\n)\ntotalArticles = df.count()\n\nprint(\"Distinct Articles: {0:,}\".format( totalArticles ))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# ANSWER\n\n# This version DOES include the bonus.\n\nfrom pyspark.sql.types import *\n\nschema = StructType([\n  StructField(\"project\", StringType(), False),\n  StructField(\"article\", StringType(), False),\n  StructField(\"requests\", IntegerType(), False),\n  StructField(\"bytes_served\", LongType(), False)\n])\n\ntotalArticles = (spark.read\n  .schema(schema)\n  .parquet(parquetDir)\n  .select(\"article\")\n  .distinct()\n  .count()\n)\n\nprint(\"Distinct Articles: {0:,}\".format( totalArticles ))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Verify Your Work\nRun the following cell to verify that your `DataFrame` was created properly."],"metadata":{}},{"cell_type":"code","source":["expected = 1783138\nassert totalArticles == expected, \"Expected the total to be \" + str(expected) + \" but found \" + str(totalArticles)\n"],"metadata":{},"outputs":[],"execution_count":10}],"metadata":{"name":"Solution - Exercise: Distinct Articles","notebookId":1947196994889317},"nbformat":4,"nbformat_minor":0}
