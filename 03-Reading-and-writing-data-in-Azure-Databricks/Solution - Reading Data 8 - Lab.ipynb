{"cells":[{"cell_type":"markdown","source":["# Reading Data Lab\n* The goal of this lab is to put into practice some of what you have learned about reading data with Apache Spark.\n* The instructions are provided below along with empty cells for you to do your work.\n* At the bottom of this notebook are additional cells that will help verify that your work is accurate."],"metadata":{}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Instructions\n0. Start with the file **dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv**, some random file you haven't seen yet.\n0. Read in the data and assign it to a `DataFrame` named **testDF**.\n0. Run the last cell to verify that the data was loaded correctly and to print its schema.\n0. The one untestable requirement is that you should be able to create the `DataFrame` and print its schema **without** executing a single job.\n\n**Note:** For the test to pass, the following columns should have the specified data types:\n * **prev_id**: integer\n * **curr_id**: integer\n * **n**: integer\n * **prev_title**: string\n * **curr_title**: string\n * **type**: string"],"metadata":{}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Show Your Work"],"metadata":{}},{"cell_type":"code","source":["# ANSWER\n\n# The students will actually need to do this in two steps.\nfileName = \"dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv\"\n\n# The first step will be to use inferSchema = true \n# It's the only way to figure out what the column and data types are\n(spark.read\n  .option(\"sep\", \"\\t\")\n  .option(\"header\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .csv(fileName)\n  .printSchema()\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- prev_id: integer (nullable = true)\n-- curr_id: integer (nullable = true)\n-- n: integer (nullable = true)\n-- prev_title: string (nullable = true)\n-- curr_title: string (nullable = true)\n-- type: string (nullable = true)\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# ANSWER\n\nfrom pyspark.sql.types import *\n\n# The second step is to create the schema\nschema = StructType([\n    StructField(\"prev_id\", IntegerType(), False),\n    StructField(\"curr_id\", IntegerType(), False),\n    StructField(\"n\", IntegerType(), False),\n    StructField(\"prev_title\", StringType(), False),\n    StructField(\"curr_title\", StringType(), False),\n    StructField(\"type\", StringType(), False)\n])\n\nfileName = \"dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv\"\n\n#The third step is to read the data in with the user-defined schema\ntestDF = (spark.read\n  .option(\"sep\", \"\\t\")\n  .option(\"header\", \"true\")\n  .schema(schema)\n  .csv(fileName)\n)\n\ntestDF.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- prev_id: integer (nullable = true)\n-- curr_id: integer (nullable = true)\n-- n: integer (nullable = true)\n-- prev_title: string (nullable = true)\n-- curr_title: string (nullable = true)\n-- type: string (nullable = true)\n\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Verify Your Work\nRun the following cell to verify that your `DataFrame` was created properly.\n\n**Remember:** This should execute without triggering a single job."],"metadata":{}},{"cell_type":"code","source":["testDF.printSchema()\n\ncolumns = testDF.dtypes\nassert len(columns) == 6, \"Expected 6 columns but found \" + str(len(columns))\n\nassert columns[0][0] == \"prev_id\",    \"Expected column 0 to be \\\"prev_id\\\" but found \\\"\" + columns[0][0] + \"\\\".\"\nassert columns[0][1] == \"int\",        \"Expected column 0 to be of type \\\"int\\\" but found \\\"\" + columns[0][1] + \"\\\".\"\n\nassert columns[1][0] == \"curr_id\",    \"Expected column 1 to be \\\"curr_id\\\" but found \\\"\" + columns[1][0] + \"\\\".\"\nassert columns[1][1] == \"int\",        \"Expected column 1 to be of type \\\"int\\\" but found \\\"\" + columns[1][1] + \"\\\".\"\n\nassert columns[2][0] == \"n\",          \"Expected column 2 to be \\\"n\\\" but found \\\"\" + columns[2][0] + \"\\\".\"\nassert columns[2][1] == \"int\",        \"Expected column 2 to be of type \\\"int\\\" but found \\\"\" + columns[2][1] + \"\\\".\"\n\nassert columns[3][0] == \"prev_title\", \"Expected column 3 to be \\\"prev_title\\\" but found \\\"\" + columns[3][0] + \"\\\".\"\nassert columns[3][1] == \"string\",     \"Expected column 3 to be of type \\\"string\\\" but found \\\"\" + columns[3][1] + \"\\\".\"\n\nassert columns[4][0] == \"curr_title\", \"Expected column 4 to be \\\"curr_title\\\" but found \\\"\" + columns[4][0] + \"\\\".\"\nassert columns[4][1] == \"string\",     \"Expected column 4 to be of type \\\"string\\\" but found \\\"\" + columns[4][1] + \"\\\".\"\n\nassert columns[5][0] == \"type\",       \"Expected column 5 to be \\\"type\\\" but found \\\"\" + columns[5][0] + \"\\\".\"\nassert columns[5][1] == \"string\",     \"Expected column 5 to be of type \\\"string\\\" but found \\\"\" + columns[5][1] + \"\\\".\"\n\nprint(\"Congratulations, all tests passed... that is if no jobs were triggered :-)\\n\")\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- prev_id: integer (nullable = true)\n-- curr_id: integer (nullable = true)\n-- n: integer (nullable = true)\n-- prev_title: string (nullable = true)\n-- curr_title: string (nullable = true)\n-- type: string (nullable = true)\n\nCongratulations, all tests passed... that is if no jobs were triggered :-)\n\n</div>"]}}],"execution_count":9}],"metadata":{"name":"Solution - Reading Data 8 - Lab","notebookId":1947196994889450},"nbformat":4,"nbformat_minor":0}
