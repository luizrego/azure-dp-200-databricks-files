{"cells":[{"cell_type":"markdown","source":["# Databricks Delta Time Machine & Optimization Lab Solution\n\nDatabricks&reg; Delta allows you to read, write and query data in data lakes in an efficient manner.\n\n## Learning Objectives\nIn this lab, you will:\n* Compare different versions of a Delta table using Time Machine\n* Optimize your Delta Lake to increase speed and reduce number of files\n* Describe how VACUUM handles invalid files\n\n\n## Audience\n* Primary Audience: Data Engineers\n* Secondary Audience: Data Analysts and Data Scientists\n\n## Prerequisites\n* Web browser: current versions of Google Chrome, Firefox, Safari, Microsoft Edge and\nInternet Explorer 11 on Windows 7, 8, or 10 (see <a href=\"https://docs.databricks.com/user-guide/supported-browsers.html#supported-browsers#\" target=\"_blank\">Supported Web Browsers</a>)\n* Databricks Runtime 4.2 or greater\n\n## Datasets Used\nWe will use online retail datasets from `/mnt/training/online_retail`"],"metadata":{}},{"cell_type":"markdown","source":["### Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["Because we'll be calculating some aggregates in this notebook, we'll change our partitions after shuffle from the default `200` to `8` (which is a good number for the 8 node cluster we're currently working on)."],"metadata":{}},{"cell_type":"code","source":["%python\n\nsqlContext.setConf(\"spark.sql.shuffle.partitions\", \"8\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### Check for our previous Delta Lake tables\n\nThis lab relies upon some tables created in previous Delta Lake lessons and labs. \n\nIf you get an error from either of the next two SQL queries, running the solution code for the \"2.Delta-Lake-Basics-Lab-1\" will build all necessary tables."],"metadata":{}},{"cell_type":"code","source":["%sql\n\nSELECT COUNT(*) FROM customer_counts;\nSELECT COUNT(*) FROM customer_data_delta;"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["-sandbox\n<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> **The following cell will take several minutes to execute, and is only necessary to run if you got an error in the previous cell.**"],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Delta-Lab-2-Prep\""],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["For convenience later in this lab, the paths to the files defining our existing Delta tables are provided. You can use these paths to load the data into DataFrames, if desired, though this entire lab can be completed using SQL on the existant tables."],"metadata":{}},{"cell_type":"code","source":["DeltaPath = userhome + \"/delta/customer-data/\"\nCustomerCountsPath = userhome + \"/delta/customer_counts/\""],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["**Note: This lab depends upon the complete exectuion of the notebook titled \"Open-Source-Delta-Lake\" and the \"Delta-Lake-Basics\" lab. If these tables don't exist, go back and run all cells in these notebook.**"],"metadata":{}},{"cell_type":"markdown","source":["### Time Travel\nBecause Delta Lake is version controlled, you have the option to query past versions of the data. Let's look at the history of our current Delta table."],"metadata":{}},{"cell_type":"code","source":["%sql\nDESCRIBE HISTORY customer_data_delta"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["Querying an older version is as easy as adding `VERSION AS OF desired_version`. Let's verify that our table from one version back still exists."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT COUNT(*)\nFROM customer_data_delta\nVERSION AS OF 1"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Using a single file storage system, you now have access to every version of your historical data, ensuring that your data analysts will be able to replicate their reports (and compare aggregate changes over time) and your data scientists will be able to replicate their experiments."],"metadata":{}},{"cell_type":"markdown","source":["### Check difference between versions\n\nYou want to compare how many orders from Sweden were added by your recent UPSERT to your BI table.\n\nLet's start by getting the total sum of our `total_orders` column where our country is Sweden."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\ncount = spark.sql(\"SELECT SUM(total_orders) FROM customer_counts WHERE Country='Sweden'\").collect()[0][0]\n\nprint(count)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Again, we can look at the history of our Delta table here."],"metadata":{}},{"cell_type":"code","source":["%sql\nDESCRIBE HISTORY customer_counts"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["Our original table will be version `0`. Let's write a SQL query to see how many orders we originally had from Sweden."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT SUM(total_orders)\nFROM customer_counts\nVERSION AS OF 0\nWHERE Country='Sweden'"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["We can combine these two queries and get our difference, which represents our new entries."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT SUM(total_orders) - (\n  SELECT SUM(total_orders)\n  FROM customer_counts\n  VERSION AS OF 0\n  WHERE Country='Sweden') AS new_entries\nFROM customer_counts\nWHERE Country='Sweden'"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["### OPTIMIZE and ZORDER\n\nLet's apply some of these optimizations to `../delta/customer-data/`.\n\nOur data is partitioned by `Country`.\n\nWe want to query the data for `StockCode` equal to `22301`.\n\nWe expect this query to be slow because we have to examine ALL OF `../delta/customer-data/` to find the desired `StockCode` and not just in one or two partitions.\n\nFirst, let's time the above query: you will need to form a DataFrame to pass to `preZorderQuery`."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\n%timeit preZorderQuery = spark.sql(\"SELECT * FROM customer_data_delta WHERE StockCode=22301 \").collect()"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["Compact the files and re-order by `StockCode`."],"metadata":{}},{"cell_type":"code","source":["%sql\n-- ANSWER\nOPTIMIZE customer_data_delta\nZORDER by (StockCode)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["Let's time the above query again: you will need to form a DataFrame to pass to `postZorderQuery`."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\n%timeit postZorderQuery = spark.sql(\"SELECT * FROM customer_data_delta WHERE StockCode=22301\").collect()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["### OPTIMIZE your BI table\n\nHere we'll optimize our `customer_counts` table so that we can quickly query on our `CustomerID` column."],"metadata":{}},{"cell_type":"code","source":["%sql\nOPTIMIZE customer_counts\nZORDER by (CustomerID)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["Now we can easily look at which of our customers have made the most orders."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT CustomerID, SUM(total_orders) AS total\nFROM customer_counts\nGROUP BY CustomerID\nORDER BY total DESC"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["Or we can see examine those customers that operate in the most countries."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT CustomerID, COUNT(Country) AS num_countries\nFROM customer_counts\nGROUP BY CustomerID\nSORT BY num_countries DESC"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["And then look at how many orders a customer made in each of these countries."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT Country, total_orders\nFROM customer_counts\nWHERE CustomerID = 20059"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["### Using VACUUM to clean up small files\n\nAfter we run OPTIMIZE, we have a number of uncompacted files that are no longer necessary. Running VACUUM will remove these files for us.\n\nLet's go ahead and VACUUM our `customer_data_delta` table, which points at the files in our `DeltaPath` variable.\n\nCount number of files before `VACUUM` for `Country=Sweden`."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\npreNumFiles = len(dbutils.fs.ls(DeltaPath + \"/Country=Sweden\"))\nprint(preNumFiles)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["If you try to perform an immediate `VACUUM` (using `RETAIN 0 HOURS` to clean up recently optimized files), you will get an error."],"metadata":{}},{"cell_type":"code","source":["%sql\n-- ANSWER\nVACUUM customer_data_delta RETAIN 0 HOURS;"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["This is a helfpul error. Remember that `VACUUM` is intended for occasional garbage collection. Here we'll just demonstrating that we _can_ use it to clean up files, so we'll set our configuration to allow this operation."],"metadata":{}},{"cell_type":"code","source":["spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", False)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":["Now we won't get an error when we run `VACUUM`."],"metadata":{}},{"cell_type":"code","source":["%sql\nVACUUM customer_data_delta RETAIN 0 HOURS;"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["Count how many files there are for `Country=Sweden`."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\npostNumFiles = len(dbutils.fs.ls(DeltaPath + \"/Country=Sweden\"))\nprint(postNumFiles)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":["Comparing our `preNumFiles` to `postNumFiles`, we can see that this number has reduced."],"metadata":{}}],"metadata":{"name":"Solution - Delta-Time-Machine-and-Optimization-Lab-2","notebookId":1947196994888335},"nbformat":4,"nbformat_minor":0}
