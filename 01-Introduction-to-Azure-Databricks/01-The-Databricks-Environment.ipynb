{"cells":[{"cell_type":"markdown","source":["# Work with Notebooks\n\n**Technical Accomplishments:**\n- Set the stage for learning on the Databricks platform\n- Demonstrate how to develop & execute code within a notebook\n- Introduce the Databricks File System (DBFS)\n- Introduce `dbutils`\n- Review the various \"Magic Commands\"\n- Review various built-in commands that facilitate working with the notebooks"],"metadata":{}},{"cell_type":"markdown","source":["### Feeling Lost?\nThe [Databricks Unified Support Portal](https://help.databricks.com/s/) is a great place to search forums and documentation for Databricks and Spark.\n\nDatabricks also offers [multiple tiers for dedicated support](https://databricks.com/support)."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Scala, Python, R, SQL\n\n* Each notebook is tied to a specific language: **Scala**, **Python**, **SQL** or **R**\n* Run the cell below using one of the following options:\n  * **CTRL+ENTER** or **CMD+RETURN**\n  * **SHIFT+ENTER** or **SHIFT+RETURN** to run the cell and move to the next one\n  * Using **Run Cell**, **Run All Above** or **Run All Below** as seen here<br/><img style=\"box-shadow: 5px 5px 5px 0px rgba(0,0,0,0.25); border: 1px solid rgba(0,0,0,0.25);\" src=\"https://files.training.databricks.com/images/notebook-cell-run-cmd.png\"/>\n\nFeel free to tweak the code below if you like:"],"metadata":{}},{"cell_type":"code","source":["print(\"I'm running Python!\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Magic Commands\n* Magic Commands are specific to the Databricks notebooks\n* They are very similar to Magic Commands found in comparable notebook products\n* These are built-in commands that do not apply to the notebook's default language\n* A single percent (%) symbol at the start of a cell identifies a Magic Commands"],"metadata":{}},{"cell_type":"markdown","source":["### Magic Command: &percnt;sh\nFor example, **&percnt;sh** allows us to execute shell commands on the driver"],"metadata":{}},{"cell_type":"code","source":["%sh ps | grep 'java'"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["### Magic Command: Other Languages\nAdditional Magic Commands allow for the execution of code in languages other than the notebook's default:\n* **&percnt;python**\n* **&percnt;scala**\n* **&percnt;sql**\n* **&percnt;r**"],"metadata":{}},{"cell_type":"code","source":["%scala\n\nprintln(\"Hello Scala!\")"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["%python\n\nprint(\"Hello Python!\")"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["%r\n\nprint(\"Hello R!\", quote=FALSE)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["%sql\n\nselect \"Hello SQL!\""],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["### Magic Command: &percnt;md\n\nOur favorite Magic Command **&percnt;md** allows us to render Markdown in a cell:\n* Double click this cell to begin editing it\n* Then hit `Esc` to stop editing\n\n# Title One\n## Title Two\n### Title Three\n\nThis is a test of the emergency broadcast system. This is only a test.\n\nThis is text with a **bold** word in it.\n\nThis is text with an *italicized* word in it.\n\nThis is an ordered list\n0. once\n0. two\n0. three\n\nThis is an unordered list\n* apples\n* peaches\n* bananas\n\nLinks/Embedded HTML: <a href=\"http://bfy.tw/19zq\" target=\"_blank\">What is Markdown?</a>\n\nImages:\n![Spark Engines](https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png)\n\nAnd of course, tables:\n\n| Name  | Age | Sex    |\n|-------|-----|--------|\n| Tom   | 32  | Male   |\n| Mary  | 29  | Female |\n| Dick  | 73  | Male   |\n| Sally | 55  | Female |"],"metadata":{}},{"cell_type":"markdown","source":["### Magic Command: &percnt;run\n* You can run a notebook from another notebook by using the Magic Command **%run**\n* All variables & functions defined in that other notebook will become available in your current notebook\n\nFor example, The following cell should fail to execute because the variable `username` has not yet been declared:"],"metadata":{}},{"cell_type":"code","source":["print(\"username: \" + username)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["But we can declare it and a handful of other variables and functions buy running this cell:"],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["In this case, the notebook `Classroom Setup` declares the following:\n  * The variable `username`\n  * The variable `userhome`\n  * The function `assertSparkVersion(..)`\n  * And others..."],"metadata":{}},{"cell_type":"code","source":["print(\"username: \" + username)\nprint(\"userhome: \" + userhome)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["We will use those variables and functions throughout this class.\n\nOne of the other things `Classroom Setup` does for us is to mount all the datasets needed for this class into the Databricks File System."],"metadata":{}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Databricks File System - DBFS\n* DBFS is a layer over a cloud-based object store\n* Files in DBFS are persisted to the object store\n* The lifetime of files in the DBFS are **NOT** tied to the lifetime of our cluster"],"metadata":{}},{"cell_type":"markdown","source":["### Mounting Data into DBFS\n* Mounting other object stores into DBFS gives Databricks users access via the file system\n* This is just one of many techniques for pulling data into Spark\n* The datasets needed for this class have already been mounted for us with the call to `%run \"../Includes/Classroom Setup\"`\n* We will confirm that in just a few minutes"],"metadata":{}},{"cell_type":"markdown","source":["See also <a href=\"https://docs.azuredatabricks.net/user-guide/dbfs-databricks-file-system.html\" target=\"_blank\">Databricks File System - DBFS</a>."],"metadata":{}},{"cell_type":"markdown","source":["### Databricks Utilities - dbutils\n* You can access the DBFS through the Databricks Utilities class (and other file IO routines).\n* An instance of DBUtils is already declared for us as `dbutils`.\n* For in-notebook documentation on DBUtils you can execute the command `dbutils.help()`."],"metadata":{}},{"cell_type":"markdown","source":["See also <a href=\"https://docs.azuredatabricks.net/user-guide/dbutils.html\" target=\"_blank\">Databricks Utilities - dbutils</a>"],"metadata":{}},{"cell_type":"code","source":["dbutils.help()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["Additional help is available for each sub-utility:\n* `dbutils.fs.help()`\n* `dbutils.meta.help()`\n* `dbutils.notebook.help()`\n* `dbutils.widgets.help()`\n\nLet's take a look at the file system utilities, `dbutils.fs`"],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.help()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["### dbutils.fs.mounts()\n* As previously mentioned, all our datasets should already be mounted\n* We can use `dbutils.fs.mounts()` to verify that assertion\n* This method returns a collection of `MountInfo` objects, one for each mount"],"metadata":{}},{"cell_type":"code","source":["mounts = dbutils.fs.mounts()\n\nfor mount in mounts:\n  print(mount.mountPoint + \" >> \" + mount.source)\n\nprint(\"-\"*80)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["### dbutils.fs.ls(..)\n* And now we can use `dbutils.fs.ls(..)` to view the contents of that mount\n* This method returns a collection of `FileInfo` objects, one for each item in the specified directory"],"metadata":{}},{"cell_type":"markdown","source":["See also <a href=\"https://docs.azuredatabricks.net/api/latest/dbfs.html#dbfsfileinfo\" target=\"_blank\">FileInfo</a>"],"metadata":{}},{"cell_type":"code","source":["files = dbutils.fs.ls(\"/mnt/training/\")\n\nfor fileInfo in files:\n  print(fileInfo.path)\n\nprint(\"-\"*80)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["### display(..)\n\nBesides printing each item returned from `dbutils.fs.ls(..)` we can also pass that collection to another Databricks specific command called `display(..)`."],"metadata":{}},{"cell_type":"code","source":["files = dbutils.fs.ls(\"/mnt/training/\")\n\ndisplay(files)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["The `display(..)` command is overloaded with a lot of other capabilities:\n* Presents up to 1000 records.\n* Exporting data as CSV.\n* Rendering a multitude of different graphs.\n* Rendering geo-located data on a world map.\n\nAnd as we will see later, it is also an excellent tool for previewing our data in a notebook."],"metadata":{}},{"cell_type":"markdown","source":["### Magic Command: &percnt;fs\n\nThere is at least one more trick for looking at the DBFS.\n\nIt is a wrapper around `dbutils.fs` and it is the Magic Command known as **&percnt;fs**.\n\nThe following call is equivalent to the previous call, `display( dbutils.fs.ls(\"/mnt/training\") )` - there is no real difference between the two."],"metadata":{}},{"cell_type":"code","source":["%fs ls /mnt/training"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Learning More\n\nWe like to encourage you to explore the documentation to learn more about the various features of the Databricks platform and notebooks.\n* <a href=\"https://docs.azuredatabricks.net/user-guide/index.html\" target=\"_blank\">User Guide</a>\n* <a href=\"https://docs.databricks.com/user-guide/getting-started.html\" target=\"_blank\">Getting Started with Databricks</a>\n* <a href=\"https://docs.azuredatabricks.net/user-guide/notebooks/index.html\" target=\"_blank\">User Guide / Notebooks</a>\n* <a href=\"https://docs.databricks.com/user-guide/notebooks/index.html#importing-notebooks\" target=\"_blank\">Importing notebooks - Supported Formats</a>\n* <a href=\"https://docs.azuredatabricks.net/administration-guide/index.html\" target=\"_blank\">Administration Guide</a>\n* <a href=\"https://docs.databricks.com/user-guide/clusters/index.html\" target=\"_blank\">Cluster Configuration</a>\n* <a href=\"https://docs.azuredatabricks.net/api/index.html\" target=\"_blank\">REST API</a>\n* <a href=\"https://docs.azuredatabricks.net/release-notes/index.html\" target=\"_blank\">Release Notes</a>\n* <a href=\"https://docs.azuredatabricks.net\" target=\"_blank\">And much more!</a>"],"metadata":{}}],"metadata":{"name":"01-The-Databricks-Environment","notebookId":1947196994889676},"nbformat":4,"nbformat_minor":0}
